{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9036596",
   "metadata": {},
   "source": [
    "# Analysis of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pm4py\n",
    "from pm4py.discovery import discover_petri_net_inductive\n",
    "from pm4py.conformance import fitness_token_based_replay\n",
    "from pm4py.conformance import precision_token_based_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4850c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XES files and convert them to DataFrames\n",
    "df_PTC = pm4py.convert_to_dataframe(pm4py.read_xes('../datasets_segmented/PrepaidTravelCost_segmented.xes'))\n",
    "df_RFP = pm4py.convert_to_dataframe(pm4py.read_xes('../datasets_segmented/RequestForPayments_segmented.xes'))\n",
    "df_ID = pm4py.convert_to_dataframe(pm4py.read_xes('../datasets_segmented/InternationalDeclarations_segmented.xes'))\n",
    "df_PL = pm4py.convert_to_dataframe(pm4py.read_xes('../datasets_segmented/PermitLog_segmented.xes'))\n",
    "df_DD = pm4py.convert_to_dataframe(pm4py.read_xes('../datasets_segmented/DomesticDeclarations_segmented.xes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store dataframe in a dictionary for easier iteration\n",
    "all_dfs = {\n",
    "    \"PrepaidTravelCost\": df_PTC,\n",
    "    \"RequestForPayments\": df_RFP,\n",
    "    \"InternationalDeclarations\": df_ID,\n",
    "    \"PermitLog\": df_PL,\n",
    "    \"DomesticDeclarations\": df_DD\n",
    "}\n",
    "\n",
    "# Reverse map for plotting labels\n",
    "numeric_to_role_map = {\n",
    "    0: 'UNDEFINED',\n",
    "    1: 'EMPLOYEE',\n",
    "    2: 'SUPERVISOR',\n",
    "    3: 'ADMINISTRATION',\n",
    "    4: 'BUDGET OWNER',\n",
    "    5: 'DIRECTOR',\n",
    "    6: 'PRE_APPROVER',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2be33",
   "metadata": {},
   "source": [
    "## Case duration analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case duration analysis\n",
    "print(\"Case Duration Analysis\")\n",
    "\n",
    "# List to store summary data for easier comparison\n",
    "summary_data = []\n",
    "\n",
    "# Iteration through each DataFrame and perform analysis\n",
    "for log_name, df in all_dfs.items():\n",
    "    \n",
    "    # Calculate overall log duration metrics\n",
    "    overall_mean_duration = df['case_duration_days'].mean()\n",
    "    overall_median_duration = df['case_duration_days'].median()\n",
    "\n",
    "    # Group by the numeric role and calculate metrics for each segment\n",
    "    segment_duration_stats = df.groupby('org_role_numeric')['case_duration_days'].agg(['mean', 'median', 'count']).reset_index()\n",
    "    \n",
    "    # Add role names for better readability\n",
    "    segment_duration_stats['org_role_name'] = segment_duration_stats['org_role_numeric'].map(numeric_to_role_map)\n",
    "\n",
    "    # Store summary data for overall comparison\n",
    "    for _, row in segment_duration_stats.iterrows():\n",
    "        summary_data.append({\n",
    "            'Log': log_name,\n",
    "            'Role_Numeric': row['org_role_numeric'],\n",
    "            'Role_Name': row['org_role_name'],\n",
    "            'Mean_Duration_Days': row['mean'],\n",
    "            'Median_Duration_Days': row['median'],\n",
    "            'Case_Count_in_Segment': row['count']\n",
    "        })\n",
    "        \n",
    "# Overall Comparison Table, creating a DataFrame from the summary data\n",
    "overall_duration_summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nOverall Duration Summary Across All Logs and Segments\")\n",
    "\n",
    "# Sort by median duration and display\n",
    "print(overall_duration_summary_df.sort_values(by='Median_Duration_Days', ascending=False).to_string())\n",
    "\n",
    "# Group by Role Name across all logs, aggregating the metrics\n",
    "print(\"\\n\\nStatistics per role across all Logs:\\n\")\n",
    "\n",
    "role_stats = overall_duration_summary_df.groupby('Role_Name').agg(\n",
    "    Avg_of_Median_Duration_Days=('Median_Duration_Days', 'mean'), \n",
    "    Avg_of_Mean_Duration_Days=('Mean_Duration_Days', 'mean'),     \n",
    "    Total_Cases_Associated=('Case_Count_in_Segment', 'sum')   \n",
    ").reset_index()\n",
    "\n",
    "# Sort for easier interpretation and display\n",
    "role_stats = role_stats.sort_values(by='Avg_of_Median_Duration_Days', ascending=False)\n",
    "print(role_stats.to_string(index=False))\n",
    "\n",
    "# Plotting the average of median case duration by role across all logs\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Role_Name', y='Avg_of_Median_Duration_Days', data=role_stats, palette='viridis', hue='Role_Name', legend=False)\n",
    "plt.title('Average of Median Case Duration (Days) by Role Across All Logs')\n",
    "plt.xlabel('Role Name')\n",
    "plt.ylabel('Average of Median Duration (Days)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9515932",
   "metadata": {},
   "source": [
    "## Case size analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8972a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Size Analysis\n",
    "print(\"\\nCase Size Analysis\")\n",
    "\n",
    "# List to store summary data for easier comparison\n",
    "summary_data_case_size = []\n",
    "\n",
    "# Iteration through each DataFrame and perform analysis\n",
    "for log_name, df in all_dfs.items():\n",
    "\n",
    "    # Calculate case size for each case, mergeing the size back into the DataFrame\n",
    "    case_sizes_series = df.groupby('case:id').size().rename('case_size')\n",
    "    df_with_case_size = df.merge(case_sizes_series.reset_index(), on='case:id', how='left')\n",
    "\n",
    "    # Calculate overall log case size metrics\n",
    "    unique_case_sizes_for_overall = df_with_case_size.drop_duplicates(subset=['case:id'])['case_size']\n",
    "    overall_mean_case_size = unique_case_sizes_for_overall.mean()\n",
    "    overall_median_case_size = unique_case_sizes_for_overall.median()\n",
    "\n",
    "    # Group by the numeric role and calculate case size metrics for each segment.\n",
    "    segment_case_size_stats = df_with_case_size.groupby('org_role_numeric')['case_size'].agg(\n",
    "        mean='mean',\n",
    "        median='median',\n",
    "        count='count'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Add role names\n",
    "    segment_case_size_stats['org_role_name'] = segment_case_size_stats['org_role_numeric'].map(numeric_to_role_map)\n",
    "\n",
    "    # Store summary data for overall comparison\n",
    "    for _, row in segment_case_size_stats.iterrows():\n",
    "        summary_data_case_size.append({\n",
    "            'Log': log_name,\n",
    "            'Role_Numeric': row['org_role_numeric'],\n",
    "            'Role_Name': row['org_role_name'],\n",
    "            'Mean_Case_Size': row['mean'],\n",
    "            'Median_Case_Size': row['median'],\n",
    "            'Case_Count_in_Segment': row['count']\n",
    "        })\n",
    "            \n",
    "# Overall Comparison Table, creating a DataFrame from the summary data\n",
    "overall_case_size_summary_df = pd.DataFrame(summary_data_case_size)\n",
    "print(\"\\nOverall Case Size Summary Across All Logs and Segments\")\n",
    "\n",
    "# Sort by median case size and display\n",
    "print(overall_case_size_summary_df.sort_values(by='Median_Case_Size', ascending=False).to_string())\n",
    "\n",
    "# Group by Role Name across all logs, aggregating the metrics\n",
    "print(\"\\n\\nStatistics per Role across all logs:\\n\")\n",
    "consolidated_role_size_stats = overall_case_size_summary_df.groupby('Role_Name').agg(\n",
    "    Avg_of_Median_Case_Size=('Median_Case_Size', 'mean'),\n",
    "    Avg_of_Mean_Case_Size=('Mean_Case_Size', 'mean'),\n",
    "    Total_Cases_Associated=('Case_Count_in_Segment', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Sort for easier interpretation and display\n",
    "consolidated_role_size_stats = consolidated_role_size_stats.sort_values(by='Avg_of_Median_Case_Size', ascending=False)\n",
    "print(consolidated_role_size_stats.to_string(index=False))\n",
    "\n",
    "# Plotting the average of median case size by role across all logs\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Role_Name', y='Avg_of_Median_Case_Size', data=consolidated_role_size_stats, palette='viridis', hue='Role_Name', legend=False)\n",
    "plt.title('Average of Median Case Size (Cases) by Role Across All Logs')\n",
    "plt.xlabel('Role Name')\n",
    "plt.ylabel('Average of Median Case Size (Cases)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3983f2f",
   "metadata": {},
   "source": [
    "# Reworked activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dff13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rework Analysis\n",
    "\n",
    "# List to store summary data\n",
    "summary_data_rework = []\n",
    "\n",
    "# Iteration through each DataFrame\n",
    "for log_name, df in all_dfs.items():\n",
    " \n",
    "    # Get the rework cases per activity\n",
    "    rework_per_activity = pm4py.stats.get_rework_cases_per_activity(\n",
    "        df,\n",
    "        activity_key='concept:name',\n",
    "        case_id_key='case:id',\n",
    "        timestamp_key='time:timestamp'\n",
    "    )\n",
    "    \n",
    "    # Convert the rework cases dictionary to a DataFrame\n",
    "    rework_df = pd.DataFrame.from_dict(rework_per_activity, orient='index', columns=['cases_with_rework_for_activity']).reset_index()\n",
    "    rework_df.rename(columns={'index': 'concept:name'}, inplace=True)\n",
    "    activity_role_mapping = df[['concept:name', 'org_role_numeric']].drop_duplicates().dropna(subset=['org_role_numeric'])\n",
    "    rework_by_activity_and_role = rework_df.merge(activity_role_mapping, on='concept:name', how='left')\n",
    "    \n",
    "    # Compute rework statistics per role\n",
    "    rework_stats_per_role = rework_by_activity_and_role.groupby('org_role_numeric').agg(\n",
    "        total_cases_with_rework_activities=('cases_with_rework_for_activity', 'sum')\n",
    "    ).reset_index()\n",
    "    total_cases_involved_per_role = df.groupby('org_role_numeric')['case:id'].nunique().reset_index(name='total_cases_involved')\n",
    "    rework_stats_per_role = rework_stats_per_role.merge(total_cases_involved_per_role, on='org_role_numeric', how='left').fillna(0)\n",
    "    rework_stats_per_role['percentage_cases_with_rework_by_role'] = (rework_stats_per_role['total_cases_with_rework_activities'] / rework_stats_per_role['total_cases_involved']) * 100\n",
    "    rework_stats_per_role['Role_Name'] = rework_stats_per_role['org_role_numeric'].map(numeric_to_role_map)\n",
    "    \n",
    "    # Iterate through the rework statistics and append to summary data\n",
    "    for _, row in rework_stats_per_role.iterrows():\n",
    "        summary_data_rework.append({\n",
    "            'Log': log_name,\n",
    "            'Role_Numeric': row['org_role_numeric'],\n",
    "            'Role_Name': row['Role_Name'],\n",
    "            'Total_Cases_with_Rework_Activities_for_Role': row['total_cases_with_rework_activities'],\n",
    "            'Total_Cases_Involved_for_Role': row['total_cases_involved'],\n",
    "            'Percentage_Cases_with_Rework_by_Role': row['percentage_cases_with_rework_by_role']\n",
    "        })\n",
    "\n",
    "overall_rework_summary_df = pd.DataFrame(summary_data_rework)\n",
    "print(\"Rework statistics per role across all logs:\\n\")\n",
    "\n",
    "# Aggregate the rework statistics across all logs\n",
    "consolidated_rework_stats = overall_rework_summary_df.groupby('Role_Name').agg(\n",
    "    Avg_Percentage_Cases_with_Rework_by_Role=('Percentage_Cases_with_Rework_by_Role', 'mean'),\n",
    "    Total_Rework_Cases_Associated=('Total_Cases_with_Rework_Activities_for_Role', 'sum'),\n",
    "    Total_Cases_Involved_Overall=('Total_Cases_Involved_for_Role', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Sorting\n",
    "consolidated_rework_stats = consolidated_rework_stats.sort_values(by='Avg_Percentage_Cases_with_Rework_by_Role', ascending=False)\n",
    "\n",
    "# Display\n",
    "print(consolidated_rework_stats.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Role_Name', y='Avg_Percentage_Cases_with_Rework_by_Role', data=consolidated_rework_stats, palette='viridis', hue='Role_Name', legend=False)\n",
    "plt.title('Average Percentage of Cases with Rework Activities per Role (Across All Logs)')\n",
    "plt.xlabel('Role Name')\n",
    "plt.ylabel('Average % of Cases with Rework Activities')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08d65b",
   "metadata": {},
   "source": [
    "# Conformance Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd498346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conformance Checking Analysis using Inductive Miner Petri Net and Token-Based Replay\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "print(\"Conformance Checking Analysis using Inductive Miner Petri Net and Token-Based Replay\")\n",
    "summary_conformance_data = []\n",
    "\n",
    "for log_name, df in all_dfs.items():\n",
    "    print(f\"\\nAnalyzing Log: {log_name}\")\n",
    "    \n",
    "    # Convert DataFrame to Event Log\n",
    "    log = pm4py.convert_to_event_log(df, case_id_key='case:id', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "\n",
    "    # Discover the Petri net using Inductive Miner\n",
    "    net, im, fm = discover_petri_net_inductive(log) \n",
    "    \n",
    "    # Fitness computation using fitness_token_based_replay\n",
    "    fitness_score = None\n",
    "    fitness_results = fitness_token_based_replay(log, net, im, fm)\n",
    "    if isinstance(fitness_results, dict) and 'log_fitness' in fitness_results: # Avoid potential KeyError\n",
    "        fitness_score = fitness_results['log_fitness']\n",
    "\n",
    "    # Precision computation using precision_token_based_replay\n",
    "    precision_score = None\n",
    "    precision_score = precision_token_based_replay(log, net, im, fm)\n",
    "    if isinstance(precision_score, dict) and 'precision' in precision_score: # Avoid potential KeyError\n",
    "        precision_score = precision_score['precision']\n",
    "    \n",
    "    # Summary\n",
    "    summary_conformance_data.append({\n",
    "        'Log': log_name,\n",
    "        'Fitness': fitness_score,\n",
    "        'Precision': precision_score\n",
    "    })\n",
    "\n",
    "# DataFrame for overall conformance summary, displaying fitness and precision scores\n",
    "overall_conformance_df = pd.DataFrame(summary_conformance_data)\n",
    "overall_conformance_df = overall_conformance_df.sort_values(by='Precision', ascending=False)\n",
    "print(\"\\nOverall conformance Summary Across all logs:\\n\")\n",
    "print(overall_conformance_df.to_string(index=False))\n",
    "\n",
    "# Plotting the conformance results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Fitness Plot\n",
    "sns.barplot(x='Log', y='Fitness', data=overall_conformance_df, palette='viridis', hue='Log', legend=False, ax=axes[0])\n",
    "axes[0].set_title('Log Fitness')\n",
    "axes[0].set_xlabel('Log Name')\n",
    "axes[0].set_ylabel('Fitness (0-1)')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].tick_params(axis='x', rotation=45) \n",
    "\n",
    "# Precision Plot\n",
    "sns.barplot(x='Log', y='Precision', data=overall_conformance_df, palette='plasma', hue='Log', legend=False, ax=axes[1])\n",
    "axes[1].set_title('Log Precision')\n",
    "axes[1].set_xlabel('Log Name')\n",
    "axes[1].set_ylabel('Precision (0-1)')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa29c5",
   "metadata": {},
   "source": [
    "# Rejection rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rejection rates and involved roles analysis\n",
    "\n",
    "rejected_cases_summary_list = []\n",
    "\n",
    "# Iteration through each Dataframe\n",
    "for log_name, df_log in all_dfs.items():\n",
    "    \n",
    "    # Preprocess the DataFrame to ensure correct types, create a copy to avoid modifying the original\n",
    "    df_log_processed = df_log.copy()\n",
    "    df_log_processed['concept:name'] = df_log_processed['concept:name'].astype(str)\n",
    "    df_log_processed['org_role_numeric'] = pd.to_numeric(df_log_processed['org_role_numeric'], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    # Filter the DataFrame for activities that contain 'REJECTED'\n",
    "    rejected_activities_in_log = df_log_processed[df_log_processed['concept:name'].str.contains('REJECTED', na=False)]\n",
    "\n",
    "    # If there are rejected activities in the log\n",
    "    if not rejected_activities_in_log.empty:\n",
    "\n",
    "        # Calculate some statistics\n",
    "        unique_rejected_cases = rejected_activities_in_log['case:id'].nunique()\n",
    "        total_cases_in_log = df_log_processed['case:id'].nunique()\n",
    "        percentage_cases_with_rejection = (unique_rejected_cases / total_cases_in_log) * 100 \n",
    "        involved_roles_numeric = rejected_activities_in_log['org_role_numeric'].unique()\n",
    "        involved_roles_names = [numeric_to_role_map.get(role_num, 'UNKNOWN_ROLE') for role_num in involved_roles_numeric]\n",
    "        involved_roles_str = ', '.join(sorted(set(involved_roles_names)))\n",
    "        total_rejected_activities_count = len(rejected_activities_in_log)\n",
    "\n",
    "        # Append the summary for this log\n",
    "        rejected_cases_summary_list.append({\n",
    "            'Log_Name': log_name,\n",
    "            'Unique_Cases_with_Rejection': unique_rejected_cases,\n",
    "            'Percentage_Cases_with_Rejection_in_Log': percentage_cases_with_rejection,\n",
    "            'Total_Rejected_Activities': total_rejected_activities_count,\n",
    "            'Involved_Roles': involved_roles_str\n",
    "        })\n",
    "    # If there are no rejected activities in the log\n",
    "    else:\n",
    "        # Append a summary indicating no rejections found\n",
    "        rejected_cases_summary_list.append({\n",
    "            'Log_Name': log_name,\n",
    "            'Unique_Cases_with_Rejection': 0,\n",
    "            'Percentage_Cases_with_Rejection_in_Log': 0,\n",
    "            'Total_Rejected_Activities': 0,\n",
    "            'Involved_Roles': 'No Rejections Found'\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the summary list, ordering by percentage of cases with rejection\n",
    "final_consolidated_rejections_df = pd.DataFrame(rejected_cases_summary_list)\n",
    "final_consolidated_rejections_df = final_consolidated_rejections_df.sort_values(\n",
    "    by='Percentage_Cases_with_Rejection_in_Log', ascending=False\n",
    ")\n",
    "\n",
    "print(\"Overall rejection summary across all logs:\\n\")\n",
    "print(final_consolidated_rejections_df.to_string(index=False))\n",
    "\n",
    "# Plotting the percentage of cases with rejection in each log\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(\n",
    "    x='Log_Name',\n",
    "    y='Percentage_Cases_with_Rejection_in_Log',\n",
    "    data=final_consolidated_rejections_df,\n",
    "    palette='magma',\n",
    "    hue='Log_Name',\n",
    "    legend=False\n",
    ")\n",
    "plt.title('Percentage of cases with rejection in each log')\n",
    "plt.xlabel('Log Name')\n",
    "plt.ylabel('Percentage of rejected cases (%)')\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
